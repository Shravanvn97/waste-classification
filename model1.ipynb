{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8744a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7642f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19764 images belonging to 2 classes.\n",
      "Found 4941 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=25,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    \"dataset_mendeley\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    \"dataset_mendeley\",\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c449f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224,224,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(train_data.num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1a391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 567ms/step - accuracy: 0.9040 - loss: 0.2427 - val_accuracy: 0.9170 - val_loss: 0.2168\n",
      "Epoch 2/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 719ms/step - accuracy: 0.9290 - loss: 0.1845 - val_accuracy: 0.9118 - val_loss: 0.2271\n",
      "Epoch 3/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 533ms/step - accuracy: 0.9382 - loss: 0.1644 - val_accuracy: 0.8960 - val_loss: 0.2574\n",
      "Epoch 4/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m816s\u001b[0m 1s/step - accuracy: 0.9392 - loss: 0.1571 - val_accuracy: 0.9192 - val_loss: 0.2123\n",
      "Epoch 5/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 548ms/step - accuracy: 0.9431 - loss: 0.1500 - val_accuracy: 0.9114 - val_loss: 0.2198\n",
      "Epoch 6/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m743s\u001b[0m 1s/step - accuracy: 0.9445 - loss: 0.1418 - val_accuracy: 0.9027 - val_loss: 0.2425\n",
      "Epoch 7/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 577ms/step - accuracy: 0.9471 - loss: 0.1371 - val_accuracy: 0.8867 - val_loss: 0.2750\n",
      "Epoch 8/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 515ms/step - accuracy: 0.9490 - loss: 0.1301 - val_accuracy: 0.9039 - val_loss: 0.2451\n",
      "Epoch 9/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 494ms/step - accuracy: 0.9504 - loss: 0.1290 - val_accuracy: 0.9223 - val_loss: 0.2099\n",
      "Epoch 10/10\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 492ms/step - accuracy: 0.9528 - loss: 0.1219 - val_accuracy: 0.9144 - val_loss: 0.2162\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14698f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 592ms/step - accuracy: 0.9315 - loss: 0.1790 - val_accuracy: 0.9294 - val_loss: 0.2089\n",
      "Epoch 2/5\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 664ms/step - accuracy: 0.9432 - loss: 0.1523 - val_accuracy: 0.9197 - val_loss: 0.2356\n",
      "Epoch 3/5\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 1s/step - accuracy: 0.9490 - loss: 0.1309 - val_accuracy: 0.9235 - val_loss: 0.2237\n",
      "Epoch 4/5\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 606ms/step - accuracy: 0.9542 - loss: 0.1223 - val_accuracy: 0.9304 - val_loss: 0.2213\n",
      "Epoch 5/5\n",
      "\u001b[1m618/618\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 599ms/step - accuracy: 0.9569 - loss: 0.1127 - val_accuracy: 0.9231 - val_loss: 0.2320\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a31cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"organic_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f449c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
